import pandas as pd
from snownlp import SnowNLP
from docx import Document
import re
import os
import tkinter as tk
from tkinter import filedialog
import matplotlib.pyplot as plt
import platform

# ==========================================
# 1. é…ç½®ä¸å­—ä½“è®¾ç½® (è§£å†³ä¸­æ–‡ä¹±ç )
# ==========================================
system_name = platform.system()
if system_name == "Windows":
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
elif system_name == "Darwin":  # MacOS
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
else:
    plt.rcParams['font.sans-serif'] = ['sans-serif']

plt.rcParams['axes.unicode_minus'] = False


def extract_text_from_docx(file_path):
    """ä» Word æ–‡æ¡£ä¸­æå–æ‰€æœ‰æ–‡æœ¬"""
    if not os.path.exists(file_path):
        return ""
    try:
        doc = Document(file_path)
        full_text = []
        for para in doc.paragraphs:
            if para.text.strip():
                full_text.append(para.text.strip())
        return "\n".join(full_text)
    except Exception as e:
        print(f"è¯»å–é”™è¯¯: {e}")
        return ""


def analyze_sentiment(text, period_label, source_label):
    """
    å¯¹æ–‡æœ¬è¿›è¡Œåˆ†å¥æ¸…æ´—å’Œæƒ…æ„Ÿæ‰“åˆ†
    period_label: 'å‰æœŸ' æˆ– 'åæœŸ'
    source_label: 'é‡‡è®¿' æˆ– 'çºªå½•ç‰‡' (æ–‡ä»¶å)
    """
    # 1. ç®€å•æ¸…æ´—ï¼šå»é™¤å¤šä½™ç©ºç™½å’Œå¸¸è§çš„æ—¶é—´æˆ³æ ¼å¼ (å¦‚ [12:30])
    text = re.sub(r'\[\d{2}:\d{2}.*?\]', '', text)
    text = text.replace('\n', ' ').replace('\r', ' ')

    # 2. åˆ†å¥ï¼šæŒ‰ä¸­æ–‡æ ‡ç‚¹åˆ‡åˆ†
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?]', text)

    data = []
    for sent in sentences:
        sent = sent.strip()
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„å¥å­
        if len(sent) < 4:
            continue

        # 3. æƒ…æ„Ÿæ‰“åˆ† (SnowNLP)
        try:
            s = SnowNLP(sent)
            # æ˜ å°„åˆ° -1 åˆ° 1
            score = (s.sentiments - 0.5) * 2
        except:
            score = 0.0

        data.append({
            'Period': period_label,
            'Source': source_label,
            'Sentence': sent,
            'Sentiment_Score': round(score, 4)
        })

    return data


def select_files(title):
    """å¼¹å‡ºæ–‡ä»¶é€‰æ‹©æ¡†"""
    print(f"\nè¯·é€‰æ‹©ã€{title}ã€‘çš„ Word æ–‡æ¡£ (æ”¯æŒå¤šé€‰)...")
    file_paths = filedialog.askopenfilenames(title=f"é€‰æ‹©{title}æ–‡æ¡£", filetypes=[("Word", "*.docx")])
    return file_paths


def plot_variance_comparison(stats_df):
    """
    ç»˜åˆ¶æƒ…æ„Ÿæ–¹å·®å¯¹æ¯”å›¾
    stats_df: åŒ…å« 'Period' å’Œ 'var' åˆ—çš„ DataFrame
    """
    if stats_df.empty or 'var' not in stats_df.columns:
        print("æ— æœ‰æ•ˆç»Ÿè®¡æ•°æ®ï¼Œæ— æ³•ç»˜å›¾ã€‚")
        return

    # å‡†å¤‡æ•°æ®
    periods = stats_df.index.tolist()
    variances = stats_df['var'].fillna(0).tolist()

    # è®¾ç½®é¢œè‰²ï¼šå‰æœŸçº¢è‰²(æ³¢åŠ¨å¤§)ï¼ŒåæœŸç»¿è‰²(å¹³ç¨³)
    colors = ['#d62728' if 'å‰æœŸ' in str(p) else '#2ca02c' for p in periods]

    # åˆ›å»ºç”»å¸ƒ
    plt.figure(figsize=(10, 6), dpi=120)

    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    bars = plt.bar(periods, variances, color=colors, alpha=0.8, width=0.5)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2., height,
                 f'{height:.4f}',
                 ha='center', va='bottom', fontsize=12, fontweight='bold')

    # è£…é¥°å›¾è¡¨
    plt.title('Faker èŒä¸šç”Ÿæ¶¯æƒ…æ„Ÿç¨³å®šæ€§å¯¹æ¯” (æ–¹å·®è¶Šå°è¶Šç¨³å®š)', fontsize=16, pad=20)
    plt.ylabel('æƒ…æ„Ÿå¾—åˆ†æ–¹å·® (Variance)', fontsize=12)
    plt.xlabel('èŒä¸šé˜¶æ®µ', fontsize=12)
    plt.grid(axis='y', linestyle='--', alpha=0.3)

    # æ·»åŠ è§£è¯»æ–‡æœ¬
    if len(variances) >= 2:
        diff = variances[0] - variances[-1]
        if diff > 0:
            note = f"ğŸ“‰ æ–¹å·®ä¸‹é™ {diff:.3f}\n(æƒ…ç»ªæ§åˆ¶åŠ›æ˜¾è‘—æå‡)"
            plt.annotate(note,
                         xy=(1, variances[-1]),
                         xytext=(0.5, max(variances) * 0.8),
                         arrowprops=dict(facecolor='gray', shrink=0.05, linestyle='--'),
                         fontsize=11, bbox=dict(boxstyle="round", fc="white", ec="gray", alpha=0.9))

    plt.tight_layout()

    # ä¿å­˜å¹¶æ˜¾ç¤º
    save_path = 'faker_variance_comparison.png'
    plt.savefig(save_path)
    print(f"\n[å¯è§†åŒ–å®Œæˆ] å›¾è¡¨å·²ä¿å­˜ä¸º: {save_path}")
    plt.show()


def main():
    print("=== Faker æ–‡æœ¬æƒ…æ„Ÿé‡åŒ–å·¥å…· (é€šç”¨ç‰ˆ + å¯è§†åŒ–) ===")

    root = tk.Tk()
    root.withdraw()

    all_data = []

    # 1. é€‰æ‹©å‰æœŸæ–‡ä»¶
    early_files = select_files("å‰æœŸ (Early Career)")
    for f in early_files:
        print(f"æ­£åœ¨å¤„ç†å‰æœŸæ–‡æ¡£: {os.path.basename(f)}...")
        text = extract_text_from_docx(f)
        if text:
            all_data.extend(analyze_sentiment(text, "å‰æœŸ", os.path.basename(f)))

    # 2. é€‰æ‹©åæœŸæ–‡ä»¶
    late_files = select_files("åæœŸ (Late Career)")
    for f in late_files:
        print(f"æ­£åœ¨å¤„ç†åæœŸæ–‡æ¡£: {os.path.basename(f)}...")
        text = extract_text_from_docx(f)
        if text:
            all_data.extend(analyze_sentiment(text, "åæœŸ", os.path.basename(f)))

    # 3. å¯¼å‡ºä¸åˆ†æ
    if all_data:
        df = pd.DataFrame(all_data)
        output_file = "faker_sentiment_analysis_final.xlsx"
        df.to_excel(output_file, index=False)

        print("\n" + "=" * 30)
        print(f"å¤„ç†å®Œæˆï¼æ•°æ®å·²ä¿å­˜ä¸º: {output_file}")
        print(f"å…±æå–å¥å­: {len(df)} æ¡")
        print("=" * 30)

        # è‡ªåŠ¨è®¡ç®—æ–¹å·®
        print("\n[å…³é”®æŒ‡æ ‡é¢„è§ˆ: æƒ…ç»ªç¨³å®šæ€§åˆ†æ]")
        # èšåˆè®¡ç®—å‡å€¼å’Œæ–¹å·®
        stats = df.groupby('Period')['Sentiment_Score'].agg(['count', 'mean', 'var'])
        print(stats)

        # === æ–°å¢ï¼šè°ƒç”¨å¯è§†åŒ–å‡½æ•° ===
        plot_variance_comparison(stats)

    else:
        print("æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶æˆ–æå–å¤±è´¥ã€‚")


if __name__ == "__main__":
    main()